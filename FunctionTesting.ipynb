{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahmed Ayman Saad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Github Issues Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using LangChain Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import GitHubIssuesLoader\n",
    "\n",
    "loader = GitHubIssuesLoader(\n",
    "    repo=\"geekan/MetaGPT\",\n",
    "    access_token=\"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\",\n",
    "    state=\"all\",\n",
    "    comments=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://github.com/geekan/MetaGPT/issues/135', 'title': 'failed to launch chromium browser process errors', 'creator': 'lopezdp', 'created_at': '2023-08-07T05:03:12Z', 'comments': 1, 'state': 'closed', 'labels': [], 'assignee': None, 'milestone': None, 'locked': False, 'number': 135, 'is_pull_request': False}\n"
     ]
    }
   ],
   "source": [
    "print(docs[3].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[3].page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: Can't retrive the issues comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Github API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = \"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\"\n",
    "username = \"geekan\"\n",
    "repository = \"MetaGPT\"\n",
    "\n",
    "base_url = \"https://api.github.com\"\n",
    "headers = {\n",
    "        \"Authorization\": f\"token {access_token}\"\n",
    "    }\n",
    "url = f\"{base_url}/repos/{username}/{repository}/issues?state=all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://api.github.com/repos/geekan/MetaGPT/issues/146',\n",
       " 'repository_url': 'https://api.github.com/repos/geekan/MetaGPT',\n",
       " 'labels_url': 'https://api.github.com/repos/geekan/MetaGPT/issues/146/labels{/name}',\n",
       " 'comments_url': 'https://api.github.com/repos/geekan/MetaGPT/issues/146/comments',\n",
       " 'events_url': 'https://api.github.com/repos/geekan/MetaGPT/issues/146/events',\n",
       " 'html_url': 'https://github.com/geekan/MetaGPT/issues/146',\n",
       " 'id': 1839984115,\n",
       " 'node_id': 'I_kwDOJ182U85tq-3z',\n",
       " 'number': 146,\n",
       " 'title': 'Review about MetaGPT',\n",
       " 'user': {'login': 'Kashif-Raza6',\n",
       "  'id': 96944736,\n",
       "  'node_id': 'U_kgDOBcdCYA',\n",
       "  'avatar_url': 'https://avatars.githubusercontent.com/u/96944736?v=4',\n",
       "  'gravatar_id': '',\n",
       "  'url': 'https://api.github.com/users/Kashif-Raza6',\n",
       "  'html_url': 'https://github.com/Kashif-Raza6',\n",
       "  'followers_url': 'https://api.github.com/users/Kashif-Raza6/followers',\n",
       "  'following_url': 'https://api.github.com/users/Kashif-Raza6/following{/other_user}',\n",
       "  'gists_url': 'https://api.github.com/users/Kashif-Raza6/gists{/gist_id}',\n",
       "  'starred_url': 'https://api.github.com/users/Kashif-Raza6/starred{/owner}{/repo}',\n",
       "  'subscriptions_url': 'https://api.github.com/users/Kashif-Raza6/subscriptions',\n",
       "  'organizations_url': 'https://api.github.com/users/Kashif-Raza6/orgs',\n",
       "  'repos_url': 'https://api.github.com/users/Kashif-Raza6/repos',\n",
       "  'events_url': 'https://api.github.com/users/Kashif-Raza6/events{/privacy}',\n",
       "  'received_events_url': 'https://api.github.com/users/Kashif-Raza6/received_events',\n",
       "  'type': 'User',\n",
       "  'site_admin': False},\n",
       " 'labels': [],\n",
       " 'state': 'open',\n",
       " 'locked': False,\n",
       " 'assignee': None,\n",
       " 'assignees': [],\n",
       " 'milestone': None,\n",
       " 'comments': 3,\n",
       " 'created_at': '2023-08-07T18:13:33Z',\n",
       " 'updated_at': '2023-08-08T07:22:38Z',\n",
       " 'closed_at': None,\n",
       " 'author_association': 'NONE',\n",
       " 'active_lock_reason': None,\n",
       " 'body': 'I have created 5 projects using metagpt and in first go `cli_snake_game` worked only and all the remaining get stuck. Let me share one example over here:\\r\\nI have asked it to create a portfolio website for a developer and it created the all the project and when I tested the project I uses the old modules syntax that is creating a lot of trouble. One error I want to share here:\\r\\n![image](https://github.com/geekan/MetaGPT/assets/96944736/abfde1f6-4ebc-416a-bc46-2c97ebed0be5)\\r\\n\\r\\nfor this code I have selected code_review to `True`. For a single project it cost you around 2-3$  and at the end when you see a lot of error its disgusting. There should be web search option to get the latest information and then it should create the project.',\n",
       " 'reactions': {'url': 'https://api.github.com/repos/geekan/MetaGPT/issues/146/reactions',\n",
       "  'total_count': 2,\n",
       "  '+1': 2,\n",
       "  '-1': 0,\n",
       "  'laugh': 0,\n",
       "  'hooray': 0,\n",
       "  'confused': 0,\n",
       "  'heart': 0,\n",
       "  'rocket': 0,\n",
       "  'eyes': 0},\n",
       " 'timeline_url': 'https://api.github.com/repos/geekan/MetaGPT/issues/146/timeline',\n",
       " 'performed_via_github_app': None,\n",
       " 'state_reason': None}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues[4]\n",
    "# Body is the page_content\n",
    "# metadata: 'url': 'https://github.com/geekan/MetaGPT/issues/135', 'title': 'failed to launch chromium browser process errors', 'creator': 'lopezdp', 'created_at': '2023-08-07T05:03:12Z', 'comments': 1, 'state': 'closed', 'labels': [], 'assignee': None, 'milestone': None, 'locked': False, 'number': 135, 'is_pull_request': False}\n",
    "# metadata fields needed : url, title, creator, created_at, comments, state, labels, assignee, milestone, locked, number, is_pull_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"```\\r\\n...\\r\\nSearching for python_docx==0.8.11\\r\\nReading https://pypi.org/simple/python_docx/\\r\\nDownloading https://files.pythonhosted.org/packages/8b/a0/52729ce4aa026f31b74cc877be1d11e4ddeaa361dc7aebec148171644b33/python-docx-0.8.11.tar.gz#sha256=1105d233a0956dd8dd1e710d20b159e2d72ac3c301041b95f4d4ceb3e0ebebc4\\r\\nBest match: python-docx 0.8.11\\r\\nProcessing python-docx-0.8.11.tar.gz\\r\\nWriting /tmp/easy_install-vxdm4oep/python-docx-0.8.11/setup.cfg\\r\\nRunning python-docx-0.8.11/setup.py -q bdist_egg --dist-dir /tmp/easy_install-vxdm4oep/python-docx-0.8.11/egg-dist-tmp-ft9nlapt\\r\\nno previously-included directories found matching 'docs/.build'\\r\\nwarning: no previously-included files matching '.DS_Store' found anywhere in distribution\\r\\nwarning: no previously-included files matching '__pycache__' found anywhere in distribution\\r\\nwarning: no previously-included files matching '*.py[co]' found anywhere in distribution\\r\\n/Users/tombielecki/Library/Python/3.9/lib/python/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\\r\\n!!\\r\\n\\r\\n        ********************************************************************************\\r\\n        Please avoid running ``setup.py`` directly.\\r\\n        Instead, use pypa/build, pypa/installer, pypa/build or\\r\\n        other standards-based tools.\\r\\n\\r\\n        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\\r\\n        ********************************************************************************\\r\\n\\r\\n!!\\r\\n  self.initialize_options()\\r\\nerror: Setup script exited with error: SandboxViolation: mkdir('/private/var/root/Library/Caches/com.apple.python/private, 511) {}\\r\\n\\r\\nThe package setup script has attempted to modify files on your system\\r\\nthat are not within the EasyInstall build area, and has been aborted.\\r\\n\\r\\nThis package cannot be safely installed by EasyInstall, and may not\\r\\nsupport alternate installation locations even if you run its setup\\r\\nscript by hand.  Please inform the package's author and the EasyInstall\\r\\nmaintainers to find out if a fix or workaround is available.\\r\\n```\\r\\n\\r\\n(I then manually run this command and rerun setup.py)\\r\\n\\r\\n`error: Setup script exited with error: SandboxViolation: mkdir('/private/var/root/Library/Caches/com.apple.python/private/tmp', 511) {}\\r\\n`\\r\\n(I then manually run this command and rerun setup.py)\\r\\n\\r\\n`error: Setup script exited with error: SandboxViolation: mkdir('/private/var/root/Library/Caches/com.apple.python/private/tmp/easy_install-vxdm4oep', 511) {}\\r\\n`\\r\\n(these easy_install folders have unique names so I can't fix this step manually)\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues[3]['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for issue in issues:\n",
    "    urlIssue = issue['comments_url']\n",
    "    response = requests.get(urlIssue, headers=headers)\n",
    "    print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://api.github.com/repos/geekan/MetaGPT/issues/comments/1667234342',\n",
       "  'html_url': 'https://github.com/geekan/MetaGPT/issues/135#issuecomment-1667234342',\n",
       "  'issue_url': 'https://api.github.com/repos/geekan/MetaGPT/issues/135',\n",
       "  'id': 1667234342,\n",
       "  'node_id': 'IC_kwDOJ182U85jX_om',\n",
       "  'user': {'login': 'lopezdp',\n",
       "   'id': 5707191,\n",
       "   'node_id': 'MDQ6VXNlcjU3MDcxOTE=',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/5707191?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/lopezdp',\n",
       "   'html_url': 'https://github.com/lopezdp',\n",
       "   'followers_url': 'https://api.github.com/users/lopezdp/followers',\n",
       "   'following_url': 'https://api.github.com/users/lopezdp/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/lopezdp/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/lopezdp/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/lopezdp/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/lopezdp/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/lopezdp/repos',\n",
       "   'events_url': 'https://api.github.com/users/lopezdp/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/lopezdp/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'created_at': '2023-08-07T05:59:50Z',\n",
       "  'updated_at': '2023-08-07T05:59:50Z',\n",
       "  'author_association': 'NONE',\n",
       "  'body': 'I used the following:\\r\\n\\r\\n`brew install chromium && which chromium`\\r\\n\\r\\nI obtained the path where chromium was installed, then I replaced the `executablePath` values in `/config/puppeteer-config.json` with the values obtained from the terminal after chromium installation and it worked.',\n",
       "  'reactions': {'url': 'https://api.github.com/repos/geekan/MetaGPT/issues/comments/1667234342/reactions',\n",
       "   'total_count': 0,\n",
       "   '+1': 0,\n",
       "   '-1': 0,\n",
       "   'laugh': 0,\n",
       "   'hooray': 0,\n",
       "   'confused': 0,\n",
       "   'heart': 0,\n",
       "   'rocket': 0,\n",
       "   'eyes': 0},\n",
       "  'performed_via_github_app': None}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean impelmentation of the above functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timezone\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "access_token = \"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\"\n",
    "username = \"geekan\"\n",
    "repository = \"MetaGPT\"\n",
    "\n",
    "base_url = \"https://api.github.com\"\n",
    "headers = {\n",
    "        \"Authorization\": f\"token {access_token}\"\n",
    "    }\n",
    "lastUpdated = None\n",
    "url = f\"{base_url}/repos/{username}/{repository}/issues?state=all&since={lastUpdated}\" if lastUpdated else f\"{base_url}/repos/{username}/{repository}/issues?state=all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIssues():\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to get issues. Error: {e}\")\n",
    "        return None\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        issues = response.json()\n",
    "        lastUpdated = datetime.now(timezone.utc)\n",
    "        return issues\n",
    "    else:\n",
    "        print(f\"Failed to get issues. Status code: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "def getIssueComments(issue):\n",
    "    issueUrl = issue[\"comments_url\"]\n",
    "    try:\n",
    "        response = requests.get(issueUrl, headers=headers)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to get issue comments. Error: {e}\")\n",
    "        return None\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        comments = response.json()\n",
    "        return comments\n",
    "    else:\n",
    "        print(f\"Failed to get issue comments. Status code: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "def cleanComments(comments):\n",
    "    # cleaned_comments = []\n",
    "    # for comment in comments:\n",
    "    #     newComment = {}\n",
    "    #     newComment[\"body\"] = comment[\"body\"]\n",
    "    #     newComment[\"user\"] = comment[\"user\"][\"login\"]\n",
    "    #     newComment[\"created_at\"] = comment[\"created_at\"]\n",
    "    #     cleaned_comments.append(newComment)\n",
    "    # return cleaned_comments\n",
    "    df = pd.DataFrame(comments)\n",
    "    df[\"user\"] = df[\"user\"].apply(lambda x: x[\"login\"])\n",
    "    cleanedComments = df[[\"body\", \"user\", \"created_at\"]].to_dict(\"records\")\n",
    "    return cleanedComments\n",
    "\n",
    "def cleanIssues(issues):\n",
    "    df = pd.DataFrame(issues)\n",
    "    df[\"user\"] = df[\"user\"].apply(lambda x: x[\"login\"])\n",
    "    cleanedIssues = df[[\"title\", \"body\", \"user\", \"created_at\", \"number\", \"state\", \"labels\", \"comments\", \"comment_data\"]].to_dict(\"records\")\n",
    "    return cleanedIssues\n",
    "\n",
    "def getIssuesComments(issues):\n",
    "    for issue in issues:\n",
    "        if issue[\"comments\"] > 0:\n",
    "            comments = getIssueComments(issue)\n",
    "            if comments:\n",
    "                issue[\"comment_data\"] = cleanComments(comments)\n",
    "        else:\n",
    "            issue[\"comment_data\"] = []\n",
    "    issues = cleanIssues(issues)\n",
    "    return issues\n",
    "\n",
    "def process_issue(issue):\n",
    "    comments = getIssueComments(issue)\n",
    "    if comments:\n",
    "        issue[\"comment_data\"] = cleanComments(comments)\n",
    "    else:\n",
    "        issue[\"comment_data\"] = []\n",
    "\n",
    "def getIssuesCommentsParallel(issues):\n",
    "    with concurrent.futures.ThreadPoolExecutor(maxWorkers=32) as executor:\n",
    "        futures = [executor.submit(process_issue, issue) for issue in issues]\n",
    "\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            pass  # We are just waiting for all tasks to complete\n",
    "\n",
    "    issues = cleanIssues(issues)\n",
    "    return issues\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33452\\3989041805.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m     \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\runners.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \"\"\"\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         raise RuntimeError(\n\u001b[0m\u001b[0;32m     34\u001b[0m             \"asyncio.run() cannot be called from a running event loop\")\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "access_token = \"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\"\n",
    "username = \"geekan\"\n",
    "repository = \"MetaGPT\"\n",
    "\n",
    "base_url = \"https://api.github.com\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"token {access_token}\"\n",
    "}\n",
    "lastUpdated = None\n",
    "url = f\"{base_url}/repos/{username}/{repository}/issues?state=all&since={lastUpdated}\" if lastUpdated else f\"{base_url}/repos/{username}/{repository}/issues?state=all\"\n",
    "\n",
    "\n",
    "async def get(url, headers):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url, headers=headers) as response:\n",
    "            try:\n",
    "                response.raise_for_status()\n",
    "                return await response.json()\n",
    "            except aiohttp.ClientError as e:\n",
    "                print(f\"Failed to get data from {url}. Error: {e}\")\n",
    "                return None\n",
    "\n",
    "\n",
    "async def getIssues():\n",
    "    try:\n",
    "        response = await get(url, headers)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get issues. Error: {e}\")\n",
    "        return None\n",
    "\n",
    "    if response:\n",
    "        issues = response\n",
    "        return issues\n",
    "    else:\n",
    "        print(f\"Failed to get issues.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "async def getIssueComments(issue, headers):\n",
    "    issueUrl = issue[\"comments_url\"]\n",
    "    try:\n",
    "        response = await get(issueUrl, headers)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get issue comments. Error: {e}\")\n",
    "        return None\n",
    "\n",
    "    if response:\n",
    "        return response\n",
    "    else:\n",
    "        print(f\"Failed to get issue comments.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def cleanComments(comment):\n",
    "    newComment = {}\n",
    "    newComment[\"body\"] = comment[\"body\"]\n",
    "    newComment[\"user\"] = comment[\"user\"][\"login\"]\n",
    "    newComment[\"created_at\"] = comment[\"created_at\"]\n",
    "    return newComment\n",
    "\n",
    "\n",
    "async def getIssuesComments(issues):\n",
    "    tasks = []\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for issue in issues:\n",
    "            if issue[\"comments\"] > 0:\n",
    "                task = asyncio.ensure_future(getIssueComments(issue, headers))\n",
    "                tasks.append(task)\n",
    "        comments_list = await asyncio.gather(*tasks)\n",
    "        for issue, comments in zip(issues, comments_list):\n",
    "            if issue[\"comments\"] > 0 and comments:\n",
    "                issue[\"comment_data\"] = list(map(cleanComments, comments))\n",
    "            newIssue = {\n",
    "                \"title\": issue[\"title\"],\n",
    "                \"body\": issue[\"body\"],\n",
    "                \"user\": issue[\"user\"][\"login\"],\n",
    "                \"created_at\": issue[\"created_at\"],\n",
    "                \"number\": issue[\"number\"],\n",
    "                \"state\": issue[\"state\"],\n",
    "                \"labels\": issue[\"labels\"],\n",
    "                \"comments\": issue[\"comments\"],\n",
    "            }\n",
    "            issue.update(newIssue)\n",
    "    return issues\n",
    "\n",
    "\n",
    "async def main():\n",
    "    issues = await getIssues()\n",
    "    if issues:\n",
    "        updated_issues = await getIssuesComments(issues)\n",
    "        print(updated_issues)\n",
    "    else:\n",
    "        print(\"No issues found.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def getIssuesCall():\n",
    "    issues = await getIssues()\n",
    "    if issues:\n",
    "            updated_issues = await getIssuesComments(issues)\n",
    "            print(updated_issues)\n",
    "    else:\n",
    "        print(\"No issues found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = getIssues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = getIssuesComments(issues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = getIssues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = getIssuesCommentsParallel(issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': '希望取得联系',\n",
       "  'body': '尊敬的[MetaGPT](https://github.com/geekan/MetaGPT) 应用开发者，我是 InternLM 社区开发者&志愿者尖米, 大佬开源的工作对我的启发很大，希望可以探讨使用 InternLM 实现[MetaGPT](https://github.com/geekan/MetaGPT) 的可能性和实现路径，我的微信是mzm312，希望可以取得联系进行更深度的交流；',\n",
       "  'user': 'JimmyMa99',\n",
       "  'created_at': '2023-08-08T09:03:04Z',\n",
       "  'number': 151,\n",
       "  'state': 'open',\n",
       "  'labels': [],\n",
       "  'comments': 0,\n",
       "  'comment_data': []},\n",
       " {'title': 'Installation issue on Wnd11 miniconda (Python 3.10)',\n",
       "  'body': '[requirements.txt](https://github.com/geekan/MetaGPT/files/12288657/requirements.txt)\\r\\nDear Geekan,\\r\\nI fixed this installation by changed the requirements.txt. I like your idea, so send it back you. Hope that helps.',\n",
       "  'user': 'HuangKaibo2017',\n",
       "  'created_at': '2023-08-08T07:45:46Z',\n",
       "  'number': 150,\n",
       "  'state': 'open',\n",
       "  'labels': [],\n",
       "  'comments': 0,\n",
       "  'comment_data': []},\n",
       " {'title': 'MetaGPT and possible enhancements',\n",
       "  'body': \"I have used your interesting software and it produces very nice output.\\r\\nI propose these possible ehancements.\\r\\n1) To provide the possibility, in an iterative fashion, to enhance the software product itself and update all it's architectural views and implementation details until the user stop this iteration.\\r\\n2) To save checkpoints of such iteration with some versioning control\\r\\n3) To provide the possibility to restart the iteration from the last checkpoint saved\\r\\n4) To analyzed the code produced and identify any possible manual modification as a part of the produced software lifecycle itself\\r\\n\\r\\nFirstly point 1.\\r\\n\\r\\nOther points are more complex.\",\n",
       "  'user': 'gnovelli',\n",
       "  'created_at': '2023-08-08T07:28:04Z',\n",
       "  'number': 149,\n",
       "  'state': 'open',\n",
       "  'labels': [],\n",
       "  'comments': 0,\n",
       "  'comment_data': []},\n",
       " {'title': 'Program does not run',\n",
       "  'body': 'python3.9 startup.py \"写一个1+1=2的程序\"\\r\\n2023-08-08 13:54:32.804 | INFO     | metagpt.config:__init__:44 - Config loading done.\\r\\n2023-08-08 13:54:36.046 | INFO     | metagpt.software_company:invest:39 - Investment: $3.0.\\r\\n2023-08-08 13:54:36.047 | INFO     | metagpt.roles.role:_act:167 - Alice(Product Manager): ready to WritePRD\\r\\n\\r\\nprogram does not run，and you can see the logs in the next line\\r\\n\\r\\n2023-08-08 13:54:36.085 | DEBUG    | metagpt.roles.role:run:237 - Bob(Architect): no news. waiting.\\r\\n2023-08-08 13:54:36.086 | DEBUG    | metagpt.roles.role:run:237 - Eve(Project Manager): no news. waiting.\\r\\n2023-08-08 13:54:36.086 | DEBUG    | metagpt.roles.role:run:237 - Alex(Engineer): no news. waiting.\\r\\n\\r\\nWhat is the reason for this?\\r\\n',\n",
       "  'user': 'xuyingtong1',\n",
       "  'created_at': '2023-08-08T05:59:51Z',\n",
       "  'number': 148,\n",
       "  'state': 'open',\n",
       "  'labels': [],\n",
       "  'comments': 2,\n",
       "  'comment_data': [{'body': 'Please refer to faq8.\\r\\nhttps://deepwisdom.feishu.cn/wiki/MsGnwQBjiif9c3koSJNcYaoSnu4',\n",
       "    'user': 'voidking',\n",
       "    'created_at': '2023-08-08T07:26:27Z'},\n",
       "   {'body': \"I met the same issue and can't find the solution from the link below:\\r\\nPlease refer to faq8.\\r\\nhttps://deepwisdom.feishu.cn/wiki/MsGnwQBjiif9c3koSJNcYaoSnu4\",\n",
       "    'user': 'HuangKaibo2017',\n",
       "    'created_at': '2023-08-08T07:51:23Z'}]},\n",
       " {'title': 'bugfix: MetaGPT quickstart doc links',\n",
       "  'body': None,\n",
       "  'user': 'voidking',\n",
       "  'created_at': '2023-08-08T03:36:32Z',\n",
       "  'number': 147,\n",
       "  'state': 'closed',\n",
       "  'labels': [],\n",
       "  'comments': 0,\n",
       "  'comment_data': []},\n",
       " {'title': 'Review about MetaGPT',\n",
       "  'body': 'I have created 5 projects using metagpt and in first go `cli_snake_game` worked only and all the remaining get stuck. Let me share one example over here:\\r\\nI have asked it to create a portfolio website for a developer and it created the all the project and when I tested the project I uses the old modules syntax that is creating a lot of trouble. One error I want to share here:\\r\\n![image](https://github.com/geekan/MetaGPT/assets/96944736/abfde1f6-4ebc-416a-bc46-2c97ebed0be5)\\r\\n\\r\\nfor this code I have selected code_review to `True`. For a single project it cost you around 2-3$  and at the end when you see a lot of error its disgusting. There should be web search option to get the latest information and then it should create the project.',\n",
       "  'user': 'Kashif-Raza6',\n",
       "  'created_at': '2023-08-07T18:13:33Z',\n",
       "  'number': 146,\n",
       "  'state': 'open',\n",
       "  'labels': [],\n",
       "  'comments': 3,\n",
       "  'comment_data': [{'body': 'It seems like that some dependencies are missing.\\r\\nDid you execute `pip install -r requirements.txt` first?',\n",
       "    'user': 'voidking',\n",
       "    'created_at': '2023-08-08T03:47:58Z'},\n",
       "   {'body': 'Yes I have installed the requirements. In some projects I have experience it writes version of some libraries that version can not be installed.',\n",
       "    'user': 'Kashif-Raza6',\n",
       "    'created_at': '2023-08-08T05:59:52Z'},\n",
       "   {'body': 'Not all the platforms and not all the python versions have specific libraries.\\r\\nMaybe you can give promt like `write a cli snake game with python version 3.9.7` to specify a version.',\n",
       "    'user': 'voidking',\n",
       "    'created_at': '2023-08-08T07:22:37Z'}]},\n",
       " {'title': 'MacOS Install Issues',\n",
       "  'body': 'MacOS Ventura 13.4 on an M1 chip\\r\\nfresh install of npm: 9.6.7\\r\\nfresh install of python: 3.11.4\\r\\nInitial run of `python setup.py install` led to numpy not found.\\r\\nSo, fresh install of pip :\\r\\n`curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\\r\\npython3 get-pip.py`\\r\\n\\r\\nSo, then I can\\r\\n`pip install numpy==1.24.3`\\r\\nthen cython needed, so\\r\\n`pip install cython`\\r\\nSo try again: `python setup.py install `\\r\\nDoes okay for a while, then:\\r\\n\\r\\n```\\r\\nCompiling pandas/io/sas/sas.pyx because it changed.\\r\\nTraceback (most recent call last):\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/sandbox.py\", line 156, in save_modules\\r\\n    yield saved\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/sandbox.py\", line 198, in setup_context\\r\\n    yield\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/sandbox.py\", line 259, in run_setup\\r\\n    _execfile(setup_script, ns)\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/sandbox.py\", line 46, in _execfile\\r\\n    exec(code, globals, locals)\\r\\n  File \"/var/folders/sg/7j9ct59j7ls4dshhg4dcxc3r0000gn/T/easy_install-zznb5k7_/pandas-1.4.1/setup.py\", line 651, in <module>\\r\\n  File \"/var/folders/sg/7j9ct59j7ls4dshhg4dcxc3r0000gn/T/easy_install-zznb5k7_/pandas-1.4.1/setup.py\", line 424, in maybe_cythonize\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/Cython/Build/Dependencies.py\", line 1114, in cythonize\\r\\n    pool = multiprocessing.Pool(\\r\\n           ^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/context.py\", line 119, in Pool\\r\\n    return Pool(processes, initializer, initargs, maxtasksperchild,\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 215, in __init__\\r\\n    self._repopulate_pool()\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 306, in _repopulate_pool\\r\\n    return self._repopulate_pool_static(self._ctx, self.Process,\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 329, in _repopulate_pool_static\\r\\n    w.start()\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 121, in start\\r\\n    self._popen = self._Popen(self)\\r\\n                  ^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/context.py\", line 288, in _Popen\\r\\n    return Popen(process_obj)\\r\\n           ^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\\r\\n    super().__init__(process_obj)\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_fork.py\", line 19, in __init__\\r\\n    self._launch(process_obj)\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_spawn_posix.py\", line 61, in _launch\\r\\n    with open(parent_w, \\'wb\\', closefd=False) as f:\\r\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/sandbox.py\", line 453, in _open\\r\\n    if mode not in (\\'r\\', \\'rt\\', \\'rb\\', \\'rU\\', \\'U\\') and not self._ok(path):\\r\\n                                                        ^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/sandbox.py\", line 464, in _ok\\r\\n    realpath = os.path.normcase(os.path.realpath(path))\\r\\n                                ^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"<frozen posixpath>\", line 415, in realpath\\r\\nTypeError: expected str, bytes or os.PathLike object, not int\\r\\n\\r\\nDuring handling of the above exception, another exception occurred:\\r\\n\\r\\nTraceback (most recent call last):\\r\\n  File \"/Users/aduchon/MetaGPT/metagpt/setup.py\", line 31, in <module>\\r\\n    setup(\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/__init__.py\", line 87, in setup\\r\\n    return distutils.core.setup(**attrs)\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/_distutils/core.py\", line 185, in setup\\r\\n    return run_commands(dist)\\r\\n           ^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\\r\\n    dist.run_commands()\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 968, in run_commands\\r\\n    self.run_command(cmd)\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/dist.py\", line 1217, in run_command\\r\\n    super().run_command(command)\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 987, in run_command\\r\\n    cmd_obj.run()\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/command/install.py\", line 74, in run\\r\\n    self.do_egg_install()\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/command/install.py\", line 131, in do_egg_install\\r\\n    cmd.run(show_deprecation=False)\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/command/easy_install.py\", line 420, in run\\r\\n    self.easy_install(spec, not self.no_deps)\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/command/easy_install.py\", line 662, in easy_install\\r\\n    return self.install_item(None, spec, tmpdir, deps, True)\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/command/easy_install.py\", line 709, in install_item\\r\\n    self.process_distribution(spec, dist, deps)\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/command/easy_install.py\", line 754, in process_distribution\\r\\n    distros = WorkingSet([]).resolve(\\r\\n              ^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pkg_resources/__init__.py\", line 789, in resolve\\r\\n    dist = best[req.key] = env.best_match(\\r\\n                           ^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pkg_resources/__init__.py\", line 1075, in best_match\\r\\n    return self.obtain(req, installer)\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pkg_resources/__init__.py\", line 1087, in obtain\\r\\n    return installer(requirement)\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/command/easy_install.py\", line 681, in easy_install\\r\\n    return self.install_item(spec, dist.location, tmpdir, deps)\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/command/easy_install.py\", line 707, in install_item\\r\\n    dists = self.install_eggs(spec, download, tmpdir)\\r\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/command/easy_install.py\", line 900, in install_eggs\\r\\n    return self.build_and_install(setup_script, setup_base)\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/command/easy_install.py\", line 1174, in build_and_install\\r\\n    self.run_setup(setup_script, setup_base, args)\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/command/easy_install.py\", line 1158, in run_setup\\r\\n    run_setup(setup_script, args)\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/sandbox.py\", line 249, in run_setup\\r\\n    with setup_context(setup_dir):\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 155, in __exit__\\r\\n    self.gen.throw(typ, value, traceback)\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/sandbox.py\", line 190, in setup_context\\r\\n    with save_modules():\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 155, in __exit__\\r\\n    self.gen.throw(typ, value, traceback)\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/sandbox.py\", line 169, in save_modules\\r\\n    saved_exc.resume()\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/sandbox.py\", line 143, in resume\\r\\n    raise exc.with_traceback(self._tb)\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/sandbox.py\", line 156, in save_modules\\r\\n    yield saved\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/sandbox.py\", line 198, in setup_context\\r\\n    yield\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/sandbox.py\", line 259, in run_setup\\r\\n    _execfile(setup_script, ns)\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/sandbox.py\", line 46, in _execfile\\r\\n    exec(code, globals, locals)\\r\\n  File \"/var/folders/sg/7j9ct59j7ls4dshhg4dcxc3r0000gn/T/easy_install-zznb5k7_/pandas-1.4.1/setup.py\", line 651, in <module>\\r\\n  File \"/var/folders/sg/7j9ct59j7ls4dshhg4dcxc3r0000gn/T/easy_install-zznb5k7_/pandas-1.4.1/setup.py\", line 424, in maybe_cythonize\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/Cython/Build/Dependencies.py\", line 1114, in cythonize\\r\\n    pool = multiprocessing.Pool(\\r\\n           ^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/context.py\", line 119, in Pool\\r\\n    return Pool(processes, initializer, initargs, maxtasksperchild,\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 215, in __init__\\r\\n    self._repopulate_pool()\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 306, in _repopulate_pool\\r\\n    return self._repopulate_pool_static(self._ctx, self.Process,\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 329, in _repopulate_pool_static\\r\\n    w.start()\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 121, in start\\r\\n    self._popen = self._Popen(self)\\r\\n                  ^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/context.py\", line 288, in _Popen\\r\\n    return Popen(process_obj)\\r\\n           ^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\\r\\n    super().__init__(process_obj)\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_fork.py\", line 19, in __init__\\r\\n    self._launch(process_obj)\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_spawn_posix.py\", line 61, in _launch\\r\\n    with open(parent_w, \\'wb\\', closefd=False) as f:\\r\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/sandbox.py\", line 453, in _open\\r\\n    if mode not in (\\'r\\', \\'rt\\', \\'rb\\', \\'rU\\', \\'U\\') and not self._ok(path):\\r\\n                                                        ^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/sandbox.py\", line 464, in _ok\\r\\n    realpath = os.path.normcase(os.path.realpath(path))\\r\\n                                ^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"<frozen posixpath>\", line 415, in realpath\\r\\nTypeError: expected str, bytes or os.PathLike object, not int\\r\\nTraceback (most recent call last):\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/resource_tracker.py\", line 209, in main\\r\\n    cache[rtype].remove(name)\\r\\nKeyError: \\'/mp-6lfz2m5c\\'\\r\\nTraceback (most recent call last):\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/resource_tracker.py\", line 209, in main\\r\\n    cache[rtype].remove(name)\\r\\nKeyError: \\'/mp-or8acqjp\\'\\r\\nTraceback (most recent call last):\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/resource_tracker.py\", line 209, in main\\r\\n    cache[rtype].remove(name)\\r\\nKeyError: \\'/mp-8gwv0zyw\\'\\r\\nTraceback (most recent call last):\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/resource_tracker.py\", line 209, in main\\r\\n    cache[rtype].remove(name)\\r\\nKeyError: \\'/mp-nd5m677u\\'\\r\\nTraceback (most recent call last):\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/resource_tracker.py\", line 209, in main\\r\\n    cache[rtype].remove(name)\\r\\nKeyError: \\'/mp-726mqf10\\'\\r\\nTraceback (most recent call last):\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/resource_tracker.py\", line 209, in main\\r\\n    cache[rtype].remove(name)\\r\\nKeyError: \\'/mp-y9_yd49y\\'\\r\\nTraceback (most recent call last):\\r\\n  File \"<string>\", line 1, in <module>\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 120, in spawn_main\\r\\n    exitcode = _main(fd, parent_sentinel)                                                                                                                                                                                                          \\r\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 128, in _main\\r\\n    preparation_data = reduction.pickle.load(from_parent)\\r\\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\nEOFError: Ran out of input\\r\\n```\\r\\n\\r\\n',\n",
       "  'user': 'aduchon',\n",
       "  'created_at': '2023-08-07T17:25:11Z',\n",
       "  'number': 145,\n",
       "  'state': 'open',\n",
       "  'labels': [],\n",
       "  'comments': 2,\n",
       "  'comment_data': [{'body': 'I have encountered the same problem. The high probability is that your pandas version does not match the pandas==1.4.1 in the current requirements.txt. You should first remove your previous pandas or start a new python environment, according to the requirements.txt The package version requires downloading.',\n",
       "    'user': 'xuyingtong1',\n",
       "    'created_at': '2023-08-08T02:34:49Z'},\n",
       "   {'body': 'The support of python3.11 is not very good. We recommend switching to python3.9, or trying the cloud environment.\\r\\nhttps://deepwisdom.feishu.cn/wiki/CyY9wdJc4iNqArku3Lncl4v8n2b\\r\\n',\n",
       "    'user': 'voidking',\n",
       "    'created_at': '2023-08-08T03:53:48Z'}]},\n",
       " {'title': 'Update run_code.py',\n",
       "  'body': 'Typo',\n",
       "  'user': 'jansalvador',\n",
       "  'created_at': '2023-08-07T15:46:36Z',\n",
       "  'number': 144,\n",
       "  'state': 'open',\n",
       "  'labels': [],\n",
       "  'comments': 0,\n",
       "  'comment_data': []},\n",
       " {'title': 'Update README_JA.md',\n",
       "  'body': None,\n",
       "  'user': 'eltociear',\n",
       "  'created_at': '2023-08-07T15:23:37Z',\n",
       "  'number': 143,\n",
       "  'state': 'open',\n",
       "  'labels': [],\n",
       "  'comments': 0,\n",
       "  'comment_data': []},\n",
       " {'title': 'Please add more roles / agents ',\n",
       "  'body': \"I would suggest to add more roles/agents to make the software development team more complete, such as: Dev Ops, UX, DBA, etc. Here's some suggested agents/roles to add: \\r\\n\\r\\n* User Experience (UX) Designer: Focuses on designing the user interface and user experience of the software.\\r\\nDevOps Engineer: Integrates development and operations processes to facilitate continuous integration and deployment.\\r\\n* Database Administrator (DBA): Manages and maintains the database systems used by the software.\\r\\n* Front-end Developer: Specializes in creating the user interface and user interactions of the software.\\r\\n* Back-end Developer: Handles server-side logic and database interactions to support the software's functionality.\\r\\n* Systems Administrator: Manages IT infrastructure and ensures smooth operations.\\r\\n\\r\\nThose roles/agents are responsible to create scripts like: Dockerfile, docker-compose.yaml, helm chart, ansible playbook, nginx / traefik config, terraform, ERD, etc. \",\n",
       "  'user': 'abdshomad',\n",
       "  'created_at': '2023-08-07T14:30:14Z',\n",
       "  'number': 142,\n",
       "  'state': 'open',\n",
       "  'labels': [],\n",
       "  'comments': 1,\n",
       "  'comment_data': [{'body': 'Good suggestion, some roles already in the roadmap.',\n",
       "    'user': 'voidking',\n",
       "    'created_at': '2023-08-08T03:49:37Z'}]},\n",
       " {'title': 'Changed The to A in README.md',\n",
       "  'body': None,\n",
       "  'user': 'Tanushriyt',\n",
       "  'created_at': '2023-08-07T14:28:35Z',\n",
       "  'number': 141,\n",
       "  'state': 'closed',\n",
       "  'labels': [],\n",
       "  'comments': 0,\n",
       "  'comment_data': []},\n",
       " {'title': 'Add MetaGPT quickstart doc links',\n",
       "  'body': 'Add MetaGPT quickstart doc links.\\r\\n- [MetaGPT quickstart](https://deepwisdom.feishu.cn/wiki/Q8ycw6J9tiNXdHk66MRcIN8Pnlg)\\r\\n- [MetaGPT快速体验](https://deepwisdom.feishu.cn/wiki/CyY9wdJc4iNqArku3Lncl4v8n2b)',\n",
       "  'user': 'voidking',\n",
       "  'created_at': '2023-08-07T12:49:31Z',\n",
       "  'number': 139,\n",
       "  'state': 'closed',\n",
       "  'labels': [],\n",
       "  'comments': 0,\n",
       "  'comment_data': []},\n",
       " {'title': 'remove config: update_costs',\n",
       "  'body': '`CALC_USAGE` default is `true`, \\r\\nIf the default `calc_usage` and `update_cost` operations fail, the subsequent execution of these two functions will be omitted.',\n",
       "  'user': 'alitrack',\n",
       "  'created_at': '2023-08-07T09:07:24Z',\n",
       "  'number': 138,\n",
       "  'state': 'open',\n",
       "  'labels': [],\n",
       "  'comments': 0,\n",
       "  'comment_data': []},\n",
       " {'title': 'bugfix: #128 Delete special charactors at filename',\n",
       "  'body': 'fix: https://github.com/geekan/MetaGPT/issues/128\\r\\nIf filename contains `\"` or `\\\\n`, delete them.',\n",
       "  'user': 'voidking',\n",
       "  'created_at': '2023-08-07T09:02:17Z',\n",
       "  'number': 137,\n",
       "  'state': 'closed',\n",
       "  'labels': [],\n",
       "  'comments': 0,\n",
       "  'comment_data': []},\n",
       " {'title': 'Create FAQ-EN',\n",
       "  'body': None,\n",
       "  'user': 'geniuslzh',\n",
       "  'created_at': '2023-08-07T07:17:31Z',\n",
       "  'number': 136,\n",
       "  'state': 'open',\n",
       "  'labels': [],\n",
       "  'comments': 0,\n",
       "  'comment_data': []},\n",
       " {'title': 'failed to launch chromium browser process errors',\n",
       "  'body': 'get errors on launch of browser process; below is the error from terminal which happens for all browser processes trying to launch.\\r\\n\\r\\n```\\r\\nINFO     | metagpt.utils.mermaid:mermaid_to_file:38 - Generating /Users/lopezdp/DevOps/Ai_MetaGPT/workspace/test_app/resources/competitive_analysis.pdf..\\r\\n\\r\\nError: Failed to launch the browser process! spawn /usr/bin/chromium ENOENT\\r\\n\\r\\n\\r\\nTROUBLESHOOTING: https://pptr.dev/troubleshooting\\r\\n\\r\\n    at ChildProcess.onClose (file:///Users/lopezdp/DevOps/Ai_MetaGPT/node_modules/@puppeteer/browsers/lib/esm/launch.js:253:24)\\r\\n    at ChildProcess.emit (node:events:513:28)\\r\\n    at Process.ChildProcess._handle.onexit (node:internal/child_process:291:12)\\r\\n    at onErrorNT (node:internal/child_process:485:16)\\r\\n    at processTicksAndRejections (node:internal/process/task_queues:83:21)\\r\\n```\\r\\n\\r\\n',\n",
       "  'user': 'lopezdp',\n",
       "  'created_at': '2023-08-07T05:03:12Z',\n",
       "  'number': 135,\n",
       "  'state': 'closed',\n",
       "  'labels': [],\n",
       "  'comments': 1,\n",
       "  'comment_data': [{'body': 'I used the following:\\r\\n\\r\\n`brew install chromium && which chromium`\\r\\n\\r\\nI obtained the path where chromium was installed, then I replaced the `executablePath` values in `/config/puppeteer-config.json` with the values obtained from the terminal after chromium installation and it worked.',\n",
       "    'user': 'lopezdp',\n",
       "    'created_at': '2023-08-07T05:59:50Z'}]},\n",
       " {'title': 'Docker - workspace mkdir permission denied',\n",
       "  'body': 'M1 Macbook Pro\\r\\n\\r\\nRunning the docker container with prompt CLI snake game. Requirements are complete and clear, then error on mkdir\\r\\n\\r\\n```\\r\\nTraceback (most recent call last):\\r\\n  File \"/app/metagpt/startup.py\", line 36, in <module>\\r\\n    fire.Fire(main)\\r\\n  File \"/usr/local/lib/python3.9/site-packages/fire/core.py\", line 141, in Fire\\r\\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\\r\\n  File \"/usr/local/lib/python3.9/site-packages/fire/core.py\", line 466, in _Fire\\r\\n    component, remaining_args = _CallAndUpdateTrace(\\r\\n  File \"/usr/local/lib/python3.9/site-packages/fire/core.py\", line 681, in _CallAndUpdateTrace\\r\\n    component = fn(*varargs, **kwargs)\\r\\n  File \"/app/metagpt/startup.py\", line 32, in main\\r\\n    asyncio.run(startup(idea, investment, n_round, code_review))\\r\\n  File \"/usr/local/lib/python3.9/asyncio/runners.py\", line 44, in run\\r\\n    return loop.run_until_complete(main)\\r\\n  File \"/usr/local/lib/python3.9/asyncio/base_events.py\", line 647, in run_until_complete\\r\\n    return future.result()\\r\\n  File \"/app/metagpt/startup.py\", line 20, in startup\\r\\n    await company.run(n_round=n_round)\\r\\n  File \"/app/metagpt/metagpt/software_company.py\", line 60, in run\\r\\n    await self.environment.run()\\r\\n  File \"/app/metagpt/metagpt/environment.py\", line 56, in run\\r\\n    await asyncio.gather(*futures)\\r\\n  File \"/app/metagpt/metagpt/roles/role.py\", line 239, in run\\r\\n    rsp = await self._react()\\r\\n  File \"/app/metagpt/metagpt/roles/role.py\", line 208, in _react\\r\\n    return await self._act()\\r\\n  File \"/app/metagpt/metagpt/roles/role.py\", line 167, in _act\\r\\n    response = await self._rc.todo.run(self._rc.important_memory)\\r\\n  File \"/app/metagpt/metagpt/actions/design_api.py\", line 142, in run\\r\\n    self._save(context, system_design)\\r\\n  File \"/app/metagpt/metagpt/actions/design_api.py\", line 130, in _save\\r\\n    self.recreate_workspace(workspace)\\r\\n  File \"/app/metagpt/metagpt/actions/design_api.py\", line 104, in recreate_workspace\\r\\n    workspace.mkdir(parents=True, exist_ok=True)\\r\\n  File \"/usr/local/lib/python3.9/pathlib.py\", line 1323, in mkdir\\r\\n    self._accessor.mkdir(self, mode)\\r\\nPermissionError: [Errno 13] Permission denied: \\'/app/metagpt/workspace/cli_snake_game\\'\\r\\n```\\r\\n\\r\\nI tried again with `docker exec -u 0 -it metagpt /bin/bash` but had the same issue',\n",
       "  'user': 'aotombielecki',\n",
       "  'created_at': '2023-08-07T03:51:49Z',\n",
       "  'number': 134,\n",
       "  'state': 'open',\n",
       "  'labels': [],\n",
       "  'comments': 1,\n",
       "  'comment_data': [{'body': 'Which host directory have you mount? If you map `/opt/metagpt/workspace:/app/metagpt/workspace`, try to `sudo chmod a+w /opt/metagpt/workspace` in your host.',\n",
       "    'user': 'voidking',\n",
       "    'created_at': '2023-08-07T06:15:18Z'}]},\n",
       " {'title': 'Setup script exited with error: SandboxViolation',\n",
       "  'body': \"```\\r\\n...\\r\\nSearching for python_docx==0.8.11\\r\\nReading https://pypi.org/simple/python_docx/\\r\\nDownloading https://files.pythonhosted.org/packages/8b/a0/52729ce4aa026f31b74cc877be1d11e4ddeaa361dc7aebec148171644b33/python-docx-0.8.11.tar.gz#sha256=1105d233a0956dd8dd1e710d20b159e2d72ac3c301041b95f4d4ceb3e0ebebc4\\r\\nBest match: python-docx 0.8.11\\r\\nProcessing python-docx-0.8.11.tar.gz\\r\\nWriting /tmp/easy_install-vxdm4oep/python-docx-0.8.11/setup.cfg\\r\\nRunning python-docx-0.8.11/setup.py -q bdist_egg --dist-dir /tmp/easy_install-vxdm4oep/python-docx-0.8.11/egg-dist-tmp-ft9nlapt\\r\\nno previously-included directories found matching 'docs/.build'\\r\\nwarning: no previously-included files matching '.DS_Store' found anywhere in distribution\\r\\nwarning: no previously-included files matching '__pycache__' found anywhere in distribution\\r\\nwarning: no previously-included files matching '*.py[co]' found anywhere in distribution\\r\\n/Users/tombielecki/Library/Python/3.9/lib/python/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\\r\\n!!\\r\\n\\r\\n        ********************************************************************************\\r\\n        Please avoid running ``setup.py`` directly.\\r\\n        Instead, use pypa/build, pypa/installer, pypa/build or\\r\\n        other standards-based tools.\\r\\n\\r\\n        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\\r\\n        ********************************************************************************\\r\\n\\r\\n!!\\r\\n  self.initialize_options()\\r\\nerror: Setup script exited with error: SandboxViolation: mkdir('/private/var/root/Library/Caches/com.apple.python/private, 511) {}\\r\\n\\r\\nThe package setup script has attempted to modify files on your system\\r\\nthat are not within the EasyInstall build area, and has been aborted.\\r\\n\\r\\nThis package cannot be safely installed by EasyInstall, and may not\\r\\nsupport alternate installation locations even if you run its setup\\r\\nscript by hand.  Please inform the package's author and the EasyInstall\\r\\nmaintainers to find out if a fix or workaround is available.\\r\\n```\\r\\n\\r\\n(I then manually run this command and rerun setup.py)\\r\\n\\r\\n`error: Setup script exited with error: SandboxViolation: mkdir('/private/var/root/Library/Caches/com.apple.python/private/tmp', 511) {}\\r\\n`\\r\\n(I then manually run this command and rerun setup.py)\\r\\n\\r\\n`error: Setup script exited with error: SandboxViolation: mkdir('/private/var/root/Library/Caches/com.apple.python/private/tmp/easy_install-vxdm4oep', 511) {}\\r\\n`\\r\\n(these easy_install folders have unique names so I can't fix this step manually)\",\n",
       "  'user': 'aotombielecki',\n",
       "  'created_at': '2023-08-07T02:43:51Z',\n",
       "  'number': 133,\n",
       "  'state': 'open',\n",
       "  'labels': [],\n",
       "  'comments': 1,\n",
       "  'comment_data': [{'body': 'Try to install by `pip install -r requirements.txt`',\n",
       "    'user': 'voidking',\n",
       "    'created_at': '2023-08-07T06:20:12Z'}]},\n",
       " {'title': 'Type Error',\n",
       "  'body': '    realpath = os.path.normcase(os.path.realpath(path))\\r\\n                                ^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"<frozen ntpath>\", line 675, in realpath\\r\\n  File \"<frozen ntpath>\", line 540, in normpath\\r\\nTypeError: expected str, bytes or os.PathLike object, not int',\n",
       "  'user': 'Kohl-Watson',\n",
       "  'created_at': '2023-08-07T00:25:47Z',\n",
       "  'number': 132,\n",
       "  'state': 'closed',\n",
       "  'labels': [],\n",
       "  'comments': 0,\n",
       "  'comment_data': []},\n",
       " {'title': \"ImportError: cannot import name 'Anthropic' from 'anthropic'\",\n",
       "  'body': 'I am following given directions, using OPENAI API (only config change I made is adding the key in key.yaml. ANy ideas?  \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nTraceback (most recent call last):\\r\\n  File \"C:\\\\metagpt\\\\startup.py\", line 7, in <module>\\r\\n    from metagpt.roles import Architect, Engineer, ProductManager, ProjectManager, QaEngineer\\r\\n  File \"C:\\\\metagpt\\\\metagpt\\\\roles\\\\__init__.py\", line 9, in <module>\\r\\n    from metagpt.roles.role import Role\\r\\n  File \"C:\\\\metagpt\\\\metagpt\\\\roles\\\\role.py\", line 16, in <module>\\r\\n    from metagpt.actions import Action, ActionOutput\\r\\n  File \"C:\\\\metagpt\\\\metagpt\\\\actions\\\\__init__.py\", line 10, in <module>\\r\\n    from metagpt.actions.action import Action\\r\\n  File \"C:\\\\metagpt\\\\metagpt\\\\actions\\\\action.py\", line 14, in <module>\\r\\n    from metagpt.llm import LLM\\r\\n  File \"C:\\\\metagpt\\\\metagpt\\\\llm.py\", line 9, in <module>\\r\\n    from metagpt.provider.anthropic_api import Claude2 as Claude\\r\\n  File \"C:\\\\metagpt\\\\metagpt\\\\provider\\\\anthropic_api.py\", line 10, in <module>\\r\\n    from anthropic import Anthropic\\r\\nImportError: cannot import name \\'Anthropic\\' from \\'anthropic\\'',\n",
       "  'user': 'halfsies1',\n",
       "  'created_at': '2023-08-06T19:48:00Z',\n",
       "  'number': 131,\n",
       "  'state': 'open',\n",
       "  'labels': [],\n",
       "  'comments': 1,\n",
       "  'comment_data': [{'body': 'Did you install the depencies first? Follow the [README](https://github.com/geekan/MetaGPT/blob/main/README.md) `Traditional Installation` section please.',\n",
       "    'user': 'voidking',\n",
       "    'created_at': '2023-08-07T06:24:24Z'}]},\n",
       " {'title': 'Error : Traceback (most recent call last):',\n",
       "  'body': '\\r\\n  File \"C:\\\\Users\\\\Willy\\\\Desktop\\\\BREAK\\\\Buddy GetC\\\\MetaGPT\\\\startup.py\", line 40, in <module>\\r\\n    fire.Fire(main)\\r\\n  File \"C:\\\\Users\\\\Willy\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\fire\\\\core.py\", line 141, in Fire     \\r\\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\\r\\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"C:\\\\Users\\\\Willy\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\fire\\\\core.py\", line 466, in _Fire    \\r\\n    component, remaining_args = _CallAndUpdateTrace(\\r\\n                                ^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"C:\\\\Users\\\\Willy\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\fire\\\\core.py\", line 681, in _CallAndUpdateTrace\\r\\n    component = fn(*varargs, **kwargs)\\r\\n                ^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"C:\\\\Users\\\\Willy\\\\Desktop\\\\BREAK\\\\Buddy GetC\\\\MetaGPT\\\\startup.py\", line 36, in main\\r\\n    asyncio.run(startup(idea, investment, n_round, code_review, run_tests))\\r\\n  File \"C:\\\\Program Files\\\\Python311\\\\Lib\\\\asyncio\\\\runners.py\", line 190, in run\\r\\n    return runner.run(main)\\r\\n           ^^^^^^^^^^^^^^^^\\r\\n  File \"C:\\\\Program Files\\\\Python311\\\\Lib\\\\asyncio\\\\runners.py\", line 118, in run\\r\\n    return self._loop.run_until_complete(task)\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"C:\\\\Program Files\\\\Python311\\\\Lib\\\\asyncio\\\\base_events.py\", line 653, in run_until_complete\\r\\n    return future.result()\\r\\n           ^^^^^^^^^^^^^^^\\r\\n  File \"C:\\\\Users\\\\Willy\\\\Desktop\\\\BREAK\\\\Buddy GetC\\\\MetaGPT\\\\startup.py\", line 24, in startup\\r\\n    await company.run(n_round=n_round)\\r\\n  File \"C:\\\\Users\\\\Willy\\\\Desktop\\\\BREAK\\\\Buddy GetC\\\\MetaGPT\\\\metagpt\\\\software_company.py\", line 60, in run      \\r\\n    await self.environment.run()\\r\\n  File \"C:\\\\Users\\\\Willy\\\\Desktop\\\\BREAK\\\\Buddy GetC\\\\MetaGPT\\\\metagpt\\\\environment.py\", line 56, in run\\r\\n    await asyncio.gather(*futures)\\r\\n  File \"C:\\\\Users\\\\Willy\\\\Desktop\\\\BREAK\\\\Buddy GetC\\\\MetaGPT\\\\metagpt\\\\roles\\\\role.py\", line 240, in run\\r\\n    rsp = await self._react()\\r\\n          ^^^^^^^^^^^^^^^^^^^\\r\\n  File \"C:\\\\Users\\\\Willy\\\\Desktop\\\\BREAK\\\\Buddy GetC\\\\MetaGPT\\\\metagpt\\\\roles\\\\role.py\", line 209, in _react        \\r\\n    return await self._act()\\r\\n           ^^^^^^^^^^^^^^^^^\\r\\n  File \"C:\\\\Users\\\\Willy\\\\Desktop\\\\BREAK\\\\Buddy GetC\\\\MetaGPT\\\\metagpt\\\\roles\\\\engineer.py\", line 206, in _act      \\r\\n    return await self._act_sp_precision()\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"C:\\\\Users\\\\Willy\\\\Desktop\\\\BREAK\\\\Buddy GetC\\\\MetaGPT\\\\metagpt\\\\roles\\\\engineer.py\", line 188, in _act_sp_precision\\r\\n    file_path = self.write_file(todo, code)\\r\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"C:\\\\Users\\\\Willy\\\\Desktop\\\\BREAK\\\\Buddy GetC\\\\MetaGPT\\\\metagpt\\\\roles\\\\engineer.py\", line 97, in write_file \\r\\n    file.parent.mkdir(parents=True, exist_ok=True)\\r\\n  File \"C:\\\\Program Files\\\\Python311\\\\Lib\\\\pathlib.py\", line 1116, in mkdir\\r\\n    os.mkdir(self, mode)\\r\\nOSError: [WinError 123] The filename, directory name, or volume label syntax is incorrect: \\'C:\\\\\\\\Users\\\\\\\\Willy\\\\\\\\Desktop\\\\\\\\BREAK\\\\\\\\Buddy GetC\\\\\\\\MetaGPT\\\\\\\\workspace\\\\\\\\\"funlike\"\\\\n\\\\\\\\\"funlike\"\\\\n\\'',\n",
       "  'user': 'RedWilly',\n",
       "  'created_at': '2023-08-06T18:54:42Z',\n",
       "  'number': 130,\n",
       "  'state': 'open',\n",
       "  'labels': [],\n",
       "  'comments': 9,\n",
       "  'comment_data': [{'body': 'What command did you execute?',\n",
       "    'user': 'voidking',\n",
       "    'created_at': '2023-08-07T06:29:47Z'},\n",
       "   {'body': 'python startup.py \"super fun snake game\" --code_review True \\r\\n',\n",
       "    'user': 'RedWilly',\n",
       "    'created_at': '2023-08-07T07:33:23Z'},\n",
       "   {'body': \"The problem was AI wanted to create a file but filename was including newline char as '\\\\n' and windows does not allow this, so program was failed and you take OSError, if files was generated, you can edit filename in python codes as well.\",\n",
       "    'user': 'GroophyLifefor',\n",
       "    'created_at': '2023-08-07T07:44:01Z'},\n",
       "   {'body': 'no the file was not generated. Also how do i fix ',\n",
       "    'user': 'RedWilly',\n",
       "    'created_at': '2023-08-07T07:57:09Z'},\n",
       "   {'body': 'The same as #128 . Pull the latest code and try again please.',\n",
       "    'user': 'voidking',\n",
       "    'created_at': '2023-08-07T09:22:54Z'},\n",
       "   {'body': '> The same as #128 . Pull the latest code and try again please.\\r\\n\\r\\nnice, \\r\\nis it possible to have the code make some changes or review  of a previous code, with an attempt to have it made a few modification',\n",
       "    'user': 'RedWilly',\n",
       "    'created_at': '2023-08-07T12:06:45Z'},\n",
       "   {'body': '> nice, is it possible to have the code make some changes or review of a previous code, with an attempt to have it made a few modification\\r\\n\\r\\nCurrently not supported. But it is in the roadmap.\\r\\n',\n",
       "    'user': 'voidking',\n",
       "    'created_at': '2023-08-07T12:35:50Z'},\n",
       "   {'body': 'I have the same issue, I\\'m on Mac with the latest version, but getting this error:\\r\\n\\r\\n```\\r\\npython startup.py \"Write a cli snake game\"\\r\\nTraceback (most recent call last):\\r\\n  File \"/Users/rosh-eth/code/ai/MetaGPT/startup.py\", line 5, in <module>\\r\\n    import fire\\r\\n  File \"/Users/rosh-eth/mambaforge/lib/python3.10/site-packages/fire-0.4.0-py3.10.egg/fire/__init__.py\", line 21, in <module>\\r\\n    from fire.core import Fire\\r\\n  File \"/Users/rosh-eth/mambaforge/lib/python3.10/site-packages/fire-0.4.0-py3.10.egg/fire/core.py\", line 67, in <module>\\r\\n    from fire import formatting\\r\\n  File \"/Users/rosh-eth/mambaforge/lib/python3.10/site-packages/fire-0.4.0-py3.10.egg/fire/formatting.py\", line 22, in <module>\\r\\n    import termcolor\\r\\nModuleNotFoundError: No module named \\'termcolor\\'\\r\\n```',\n",
       "    'user': 'rosh-eth',\n",
       "    'created_at': '2023-08-07T22:19:32Z'},\n",
       "   {'body': '> \\r\\n\\r\\ncan you try `pip install termcolor` before you run startup.py',\n",
       "    'user': 'GroophyLifefor',\n",
       "    'created_at': '2023-08-08T06:06:21Z'}]},\n",
       " {'title': 'Is there a programming language limitation to generate code to ?',\n",
       "  'body': None,\n",
       "  'user': 'amitmiran137',\n",
       "  'created_at': '2023-08-06T17:28:20Z',\n",
       "  'number': 129,\n",
       "  'state': 'open',\n",
       "  'labels': [],\n",
       "  'comments': 1,\n",
       "  'comment_data': [{'body': 'Currently only Python is supported. Support for other languages is already in the roadmap. Currently you can modify it yourself by searching for `\".*(python|pep).*`.\\r\\n',\n",
       "    'user': 'voidking',\n",
       "    'created_at': '2023-08-07T06:38:11Z'}]},\n",
       " {'title': 'OSError in engineer.py when Attempting to Create Directory',\n",
       "  'body': 'Title: OSError in engineer.py when Attempting to Create Directory\\r\\n\\r\\nIssue Description:\\r\\n\\r\\nWhen executing the _act_sp method in engineer.py, I am encountering an OSError related to the file path. The full traceback is as follows:\\r\\n\\r\\n`File \"D:\\\\My Projects\\\\metagpt\\\\metagpt\\\\roles\\\\engineer.py\", line 140, in _act_sp\\r\\n    file_path = self.write_file(todo, code)\\r\\n  File \"D:\\\\My Projects\\\\metagpt\\\\metagpt\\\\roles\\\\engineer.py\", line 97, in write_file\\r\\n    file.parent.mkdir(parents=True, exist_ok=True)\\r\\n  File \"D:\\\\anaconda3\\\\envs\\\\llm\\\\lib\\\\pathlib.py\", line 1175, in mkdir\\r\\n    self._accessor.mkdir(self, mode)\\r\\nOSError: [WinError 123] The filename, directory name, or volume label syntax is incorrect: \\'D:\\\\\\\\My Projects\\\\\\\\metagpt\\\\\\\\workspace\\\\\\\\\"ai_appointment_scheduler\"\\\\n\\\\\\\\\"ai_appointment_scheduler\"\\\\n\\'`\\r\\n\\r\\nIt appears that the issue is related to the filename, directory name, or volume label syntax. Any help in resolving this would be appreciated.\\r\\n\\r\\nWindows 11 and using Powershell with conda',\n",
       "  'user': 'cartpaul13',\n",
       "  'created_at': '2023-08-06T16:51:30Z',\n",
       "  'number': 128,\n",
       "  'state': 'closed',\n",
       "  'labels': [],\n",
       "  'comments': 3,\n",
       "  'comment_data': [{'body': \"I'm getting this same error\",\n",
       "    'user': 'zarco67',\n",
       "    'created_at': '2023-08-07T02:18:45Z'},\n",
       "   {'body': 'What command did you execute? It seems that `\\\\n` is brought when parsing the data.',\n",
       "    'user': 'voidking',\n",
       "    'created_at': '2023-08-07T06:54:18Z'},\n",
       "   {'body': '@cartpaul13 @zarco67 Pull the latest code and try again please.',\n",
       "    'user': 'voidking',\n",
       "    'created_at': '2023-08-07T09:08:55Z'}]},\n",
       " {'title': 'Update README.md',\n",
       "  'body': \"(If you don't have npm in your computer, please go to the Node.js offical website to install Node.js https://nodejs.org/ and then you will have npm tool in your computer.)\",\n",
       "  'user': 'ak8893893',\n",
       "  'created_at': '2023-08-06T15:09:51Z',\n",
       "  'number': 127,\n",
       "  'state': 'open',\n",
       "  'labels': [],\n",
       "  'comments': 0,\n",
       "  'comment_data': []},\n",
       " {'title': 'SSL certificate error',\n",
       "  'body': 'This error is about a SSL certificate but no idea how or if I should fix it. Can you guys please fix the installation steps to run MetaGPT in detailed fashion? \\r\\n\\r\\n```\\r\\n2023-08-06 17:39:23.455 | INFO     | metagpt.config:__init__:44 - Config loading done.\\r\\n2023-08-06 17:39:25.241 | INFO     | metagpt.software_company:invest:39 - Investment: $3.0.\\r\\n2023-08-06 17:39:25.241 | INFO     | metagpt.roles.role:_act:166 - Alice(Product Manager): ready to WritePRD\\r\\nTraceback (most recent call last):\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/connector.py\", line 980, in _wrap_create_connection\\r\\n    return await self._loop.create_connection(*args, **kwargs)  # type: ignore[return-value]  # noqa\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1112, in create_connection\\r\\n    transport, protocol = await self._create_connection_transport(\\r\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1145, in _create_connection_transport\\r\\n    await waiter\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/sslproto.py\", line 574, in _on_handshake_complete\\r\\n    raise handshake_exc\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/sslproto.py\", line 556, in _do_handshake\\r\\n    self._sslobj.do_handshake()\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py\", line 979, in do_handshake\\r\\n    self._sslobj.do_handshake()\\r\\nssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)\\r\\n\\r\\nThe above exception was the direct cause of the following exception:\\r\\n\\r\\nTraceback (most recent call last):\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/api_requestor.py\", line 592, in arequest_raw\\r\\n    result = await session.request(**request_kwargs)\\r\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/client.py\", line 536, in _request\\r\\n    conn = await self._connector.connect(\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/connector.py\", line 540, in connect\\r\\n    proto = await self._create_connection(req, traces, timeout)\\r\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/connector.py\", line 901, in _create_connection\\r\\n    _, proto = await self._create_direct_connection(req, traces, timeout)\\r\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/connector.py\", line 1206, in _create_direct_connection\\r\\n    raise last_exc\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/connector.py\", line 1175, in _create_direct_connection\\r\\n    transp, proto = await self._wrap_create_connection(\\r\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/connector.py\", line 982, in _wrap_create_connection\\r\\n    raise ClientConnectorCertificateError(req.connection_key, exc) from exc\\r\\naiohttp.client_exceptions.ClientConnectorCertificateError: Cannot connect to host api.openai.com:443 ssl:True [SSLCertVerificationError: (1, \\'[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)\\')]\\r\\n\\r\\nThe above exception was the direct cause of the following exception:\\r\\n\\r\\nTraceback (most recent call last):\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tenacity/_asyncio.py\", line 50, in __call__\\r\\n    result = await fn(*args, **kwargs)\\r\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Users/mertdeveci5/Desktop/Code/metagpt/metagpt/actions/action.py\", line 57, in _aask_v1\\r\\n    content = await self.llm.aask(prompt, system_msgs)\\r\\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Users/mertdeveci5/Desktop/Code/metagpt/metagpt/provider/base_gpt_api.py\", line 44, in aask\\r\\n    rsp = await self.acompletion_text(message, stream=True)\\r\\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Users/mertdeveci5/Desktop/Code/metagpt/metagpt/provider/openai_api.py\", line 32, in wrapper\\r\\n    return await f(*args, **kwargs)\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Users/mertdeveci5/Desktop/Code/metagpt/metagpt/provider/openai_api.py\", line 218, in acompletion_text\\r\\n    return await self._achat_completion_stream(messages)\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Users/mertdeveci5/Desktop/Code/metagpt/metagpt/provider/openai_api.py\", line 151, in _achat_completion_stream\\r\\n    response = await openai.ChatCompletion.acreate(\\r\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/api_resources/chat_completion.py\", line 45, in acreate\\r\\n    return await super().acreate(*args, **kwargs)\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 217, in acreate\\r\\n    response, _, api_key = await requestor.arequest(\\r\\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/api_requestor.py\", line 304, in arequest\\r\\n    result = await self.arequest_raw(\\r\\n             ^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/api_requestor.py\", line 609, in arequest_raw\\r\\n    raise error.APIConnectionError(\"Error communicating with OpenAI\") from e\\r\\nopenai.error.APIConnectionError: Error communicating with OpenAI\\r\\n\\r\\nThe above exception was the direct cause of the following exception:\\r\\n\\r\\nTraceback (most recent call last):\\r\\n  File \"/Users/mertdeveci5/Desktop/Code/metagpt/startup.py\", line 36, in <module>\\r\\n    fire.Fire(main)\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/fire/core.py\", line 141, in Fire\\r\\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\\r\\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/fire/core.py\", line 475, in _Fire\\r\\n    component, remaining_args = _CallAndUpdateTrace(\\r\\n                                ^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/fire/core.py\", line 691, in _CallAndUpdateTrace\\r\\n    component = fn(*varargs, **kwargs)\\r\\n                ^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Users/mertdeveci5/Desktop/Code/metagpt/startup.py\", line 32, in main\\r\\n    asyncio.run(startup(idea, investment, n_round, code_review))\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/runners.py\", line 190, in run\\r\\n    return runner.run(main)\\r\\n           ^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/runners.py\", line 118, in run\\r\\n    return self._loop.run_until_complete(task)\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 653, in run_until_complete\\r\\n    return future.result()\\r\\n           ^^^^^^^^^^^^^^^\\r\\n  File \"/Users/mertdeveci5/Desktop/Code/metagpt/startup.py\", line 20, in startup\\r\\n    await company.run(n_round=n_round)\\r\\n  File \"/Users/mertdeveci5/Desktop/Code/metagpt/metagpt/software_company.py\", line 60, in run\\r\\n    await self.environment.run()\\r\\n  File \"/Users/mertdeveci5/Desktop/Code/metagpt/metagpt/environment.py\", line 56, in run\\r\\n    await asyncio.gather(*futures)\\r\\n  File \"/Users/mertdeveci5/Desktop/Code/metagpt/metagpt/roles/role.py\", line 239, in run\\r\\n    rsp = await self._react()\\r\\n          ^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Users/mertdeveci5/Desktop/Code/metagpt/metagpt/roles/role.py\", line 208, in _react\\r\\n    return await self._act()\\r\\n           ^^^^^^^^^^^^^^^^^\\r\\n  File \"/Users/mertdeveci5/Desktop/Code/metagpt/metagpt/roles/role.py\", line 167, in _act\\r\\n    response = await self._rc.todo.run(self._rc.important_memory)\\r\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Users/mertdeveci5/Desktop/Code/metagpt/metagpt/actions/write_prd.py\", line 145, in run\\r\\n    prd = await self._aask_v1(prompt, \"prd\", OUTPUT_MAPPING)\\r\\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tenacity/_asyncio.py\", line 88, in async_wrapped\\r\\n    return await fn(*args, **kwargs)\\r\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tenacity/_asyncio.py\", line 47, in __call__\\r\\n    do = self.iter(retry_state=retry_state)\\r\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\r\\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tenacity/__init__.py\", line 326, in iter\\r\\n    raise retry_exc from fut.exception()\\r\\ntenacity.RetryError: RetryError[<Future at 0x17da59490 state=finished raised APIConnectionError>]\\r\\n```',\n",
       "  'user': 'mertdeveci5',\n",
       "  'created_at': '2023-08-06T14:42:14Z',\n",
       "  'number': 126,\n",
       "  'state': 'closed',\n",
       "  'labels': [],\n",
       "  'comments': 0,\n",
       "  'comment_data': []},\n",
       " {'title': 'question from beginner',\n",
       "  'body': 'Hello, I followed the instructions to deploy metagpt on my mac, while my first time testing it appears to not found specific module.\\r\\n\\r\\n File \"/metagpt/startup.py\", line 5, in <module>\\r\\n    import fire\\r\\nModuleNotFoundError: No module named \\'fire\\'\\r\\n\\r\\nCan anyone help me with this, im not familiar with coding',\n",
       "  'user': 'Teddyduann',\n",
       "  'created_at': '2023-08-06T13:38:15Z',\n",
       "  'number': 125,\n",
       "  'state': 'open',\n",
       "  'labels': [],\n",
       "  'comments': 3,\n",
       "  'comment_data': [{'body': 'Follow [README](https://github.com/geekan/MetaGPT/blob/main/README.md) `Traditional Installation` section. Install all the dependencies first.',\n",
       "    'user': 'voidking',\n",
       "    'created_at': '2023-08-06T13:59:25Z'},\n",
       "   {'body': \"Thanks for your soon reply, i reinstalled metagpt and i caught error like following : \\r\\n\\r\\nDownload error on https://pypi.org/simple/typing-inspect/: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002) -- Some packages may not be found!\\r\\nCouldn't find index page for 'typing-inspect' (maybe misspelled?)\\r\\nScanning index of all packages (this may take a while)\\r\\nReading https://pypi.org/simple/\\r\\nDownload error on https://pypi.org/simple/: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002) -- Some packages may not be found!\\r\\nNo local packages or working download links found for typing-inspect==0.8.0\\r\\nerror: Could not find suitable distribution for Requirement.parse('typing-inspect==0.8.0')\",\n",
       "    'user': 'Teddyduann',\n",
       "    'created_at': '2023-08-06T16:43:07Z'},\n",
       "   {'body': '1. Make sure your python version >= 3.9\\r\\n2. Add `--trust-host pypi.org` when install dependencies\\r\\n\\r\\nOr, you can try the docker version. \\r\\nhttps://deepwisdom.feishu.cn/wiki/Q8ycw6J9tiNXdHk66MRcIN8Pnlg\\r\\nhttps://deepwisdom.feishu.cn/wiki/CyY9wdJc4iNqArku3Lncl4v8n2b',\n",
       "    'user': 'voidking',\n",
       "    'created_at': '2023-08-07T07:00:32Z'}]},\n",
       " {'title': 'add write docstring action',\n",
       "  'body': '- Adding docstrings for Python code\\r\\n- Supporting Sphinx/Google/Numpy styles\\r\\n- Preserving the actual text of the original code associated with each node using libcst\\r\\n',\n",
       "  'user': 'shenchucheng',\n",
       "  'created_at': '2023-08-06T10:18:12Z',\n",
       "  'number': 124,\n",
       "  'state': 'closed',\n",
       "  'labels': [],\n",
       "  'comments': 3,\n",
       "  'comment_data': [{'body': 'LGTM',\n",
       "    'user': 'better629',\n",
       "    'created_at': '2023-08-07T02:44:47Z'},\n",
       "   {'body': '1. Add usage example like: \\r\\n```bash\\r\\nexport PYTHONPATH=$PYTHONPATH:$(pwd)\\r\\npython metagpt/actions/write_docstring.py workspace/cli_2048_game/cli_2048_game/game.py --overwrite\\r\\n```\\r\\n\\r\\n2. Sometimes parse code error.',\n",
       "    'user': 'voidking',\n",
       "    'created_at': '2023-08-07T08:32:13Z'},\n",
       "   {'body': 'LGTM',\n",
       "    'user': 'voidking',\n",
       "    'created_at': '2023-08-07T13:55:28Z'}]},\n",
       " {'title': 'Fixed: Removed quotes in workspace path',\n",
       "  'body': None,\n",
       "  'user': 'alitrack',\n",
       "  'created_at': '2023-08-06T07:35:16Z',\n",
       "  'number': 123,\n",
       "  'state': 'closed',\n",
       "  'labels': [],\n",
       "  'comments': 0,\n",
       "  'comment_data': []},\n",
       " {'title': 'How to continue the previous process after Sudden failure/如何继续刚才的失败进程',\n",
       "  'body': 'Sudden failure（error） near the end of project execution, such as interruption due to network issues. How to continue the previous process after network recovery, instead of completely restarting the project?\\r\\n\\r\\n项目执行接近尾声的时候突然失败，例如是网络原因导致中断。之后要网络恢复后要如何继续刚才的进程，而不是完全重新开始项目？',\n",
       "  'user': 'zezgithub',\n",
       "  'created_at': '2023-08-06T04:44:49Z',\n",
       "  'number': 122,\n",
       "  'state': 'open',\n",
       "  'labels': [],\n",
       "  'comments': 3,\n",
       "  'comment_data': [{'body': '目前是不支持的',\n",
       "    'user': 'voidking',\n",
       "    'created_at': '2023-08-06T11:10:28Z'},\n",
       "   {'body': '> 目前是不支持的\\r\\n\\r\\n后续有计划开发这个功能吗？',\n",
       "    'user': 'Hezhexi2002',\n",
       "    'created_at': '2023-08-08T03:38:50Z'},\n",
       "   {'body': '有的，在roadmap中了\\r\\nhttps://github.com/geekan/MetaGPT/blob/main/docs/ROADMAP.md',\n",
       "    'user': 'voidking',\n",
       "    'created_at': '2023-08-08T05:35:56Z'}]},\n",
       " {'title': 'fix the bug can not use proxy',\n",
       "  'body': None,\n",
       "  'user': 'flyi',\n",
       "  'created_at': '2023-08-05T21:52:40Z',\n",
       "  'number': 121,\n",
       "  'state': 'open',\n",
       "  'labels': [],\n",
       "  'comments': 0,\n",
       "  'comment_data': []}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Database Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from DB.Database import MongoDBHandler\n",
    "import dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "envValues = dotenv.dotenv_values(\"./DB/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('ClusterUrl', 'cluster0.i6oz6p5.mongodb.net'),\n",
       "             ('USERNAME', 'Ahmed'),\n",
       "             ('PASSWORD', 'admin'),\n",
       "             ('DBNAME', 'chatbot'),\n",
       "             ('GITHUB_ACCESS_TOKEN',\n",
       "              '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'),\n",
       "             ('GITHUB_USERNAME', 'pierreamir123'),\n",
       "             ('GITHUB_REPOSITORY', 'CHATBOT'),\n",
       "             ('GITHUB_BASE_URL', 'https://api.github.com')])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "envValues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_url = envValues[\"ClusterUrl\"]\n",
    "username = envValues[\"USERNAME\"]\n",
    "database_name = envValues[\"DBNAME\"]\n",
    "password = envValues[\"PASSWORD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongoHandle = MongoDBHandler(cluster_url, database_name, username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MongoDB cluster successfully!\n"
     ]
    }
   ],
   "source": [
    "mongoHandle.Connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = mongoHandle.load_all_documents(\"lastAccessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('64d514d901fd8a8fad10e96a'),\n",
       "  'name': 'githubIssuesLogger',\n",
       "  'lastAccess': 'None'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLogger.DataLogger import GithubIssuesLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1528\\3019511794.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgitLogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGithubIssuesLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FunctionTesting.ipynb'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'FunctionTesting.ipynb'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'FunctionTesting.ipynb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 4 were given"
     ]
    }
   ],
   "source": [
    "gitLogger = GithubIssuesLogger('FunctionTesting.ipynb', 'FunctionTesting.ipynb', 'FunctionTesting.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U05QEBKDVFH'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from slack_sdk import WebClient\n",
    "from slack_sdk.errors import SlackApiError\n",
    "\n",
    "import os\n",
    "\n",
    "import dotenv\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(\"./Classes/.env\")\n",
    "\n",
    "\n",
    "def get_bot_user_id():\n",
    "    \"\"\"\n",
    "    Get the bot user ID using the Slack API.\n",
    "    Returns:\n",
    "        str: The bot user ID.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize the Slack client with your bot token\n",
    "        slack_client = WebClient(token=os.environ[\"SLACK_BOT_TOKEN\"])\n",
    "        response = slack_client.auth_test()\n",
    "        return response[\"user_id\"]\n",
    "    except SlackApiError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "get_bot_user_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 17 key-value pairs and 291 tensors from /home/ahmedaymansaad/.cache/huggingface/hub/models--TheBloke--CodeLlama-7B-Instruct-GGUF/snapshots/a9b5773f1c12d146bde414169e14a6377d6021d0/codellama-7b-instruct.Q4_K_M.gguf (version GGUF V1 (support until nov 2023))\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q4_0     [  4096, 32016,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:                    output.weight f16      [  4096, 32016,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:              blk.0.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:              blk.0.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:              blk.0.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:         blk.0.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:            blk.0.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:            blk.0.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:              blk.0.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:              blk.1.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:              blk.1.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:              blk.1.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:         blk.1.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:            blk.1.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:            blk.1.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:              blk.1.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:              blk.2.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:              blk.2.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:              blk.2.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:         blk.2.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:            blk.2.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:            blk.2.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:              blk.2.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:              blk.3.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:              blk.3.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:              blk.3.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:         blk.3.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:            blk.3.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:            blk.3.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:              blk.3.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:              blk.4.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:              blk.4.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:              blk.4.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:         blk.4.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:            blk.4.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:            blk.4.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:              blk.4.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:              blk.5.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:              blk.5.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:              blk.5.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:         blk.5.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:            blk.5.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:            blk.5.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:              blk.5.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:              blk.6.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:              blk.6.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:              blk.6.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:         blk.6.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:            blk.6.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:            blk.6.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:              blk.6.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:              blk.7.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:              blk.7.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:              blk.7.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:         blk.7.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:            blk.7.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:            blk.7.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:              blk.7.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:              blk.8.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:              blk.8.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:              blk.8.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:         blk.8.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:            blk.8.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:            blk.8.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:              blk.8.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:              blk.9.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:              blk.9.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:              blk.9.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:         blk.9.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:            blk.9.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:            blk.9.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:              blk.9.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:             blk.10.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:             blk.10.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:             blk.10.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:        blk.10.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:           blk.10.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:           blk.10.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:             blk.10.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:             blk.11.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:             blk.11.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:             blk.11.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:        blk.11.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:           blk.11.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:           blk.11.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:             blk.11.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:             blk.12.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:             blk.12.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:             blk.12.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:        blk.12.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:           blk.12.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:           blk.12.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:             blk.12.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:             blk.13.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:             blk.13.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:             blk.13.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:        blk.13.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:           blk.13.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:           blk.13.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:             blk.13.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:             blk.14.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:             blk.14.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:             blk.14.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:        blk.14.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:           blk.14.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:           blk.14.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:             blk.14.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:             blk.15.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:             blk.15.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:             blk.15.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:        blk.15.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:           blk.15.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:           blk.15.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:             blk.15.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:             blk.16.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:             blk.16.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:             blk.16.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:        blk.16.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:           blk.16.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:           blk.16.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:             blk.16.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:             blk.17.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:             blk.17.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:             blk.17.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:        blk.17.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:           blk.17.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:           blk.17.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:             blk.17.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:             blk.18.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:             blk.18.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:             blk.18.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:        blk.18.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:           blk.18.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:           blk.18.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:             blk.18.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:             blk.19.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:             blk.19.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:             blk.19.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:        blk.19.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:           blk.19.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:           blk.19.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:             blk.19.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:             blk.20.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:             blk.20.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:             blk.20.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:        blk.20.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:           blk.20.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:           blk.20.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:             blk.20.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:             blk.21.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:             blk.21.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:             blk.21.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:        blk.21.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:           blk.21.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:           blk.21.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:             blk.21.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:             blk.22.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:             blk.22.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:             blk.22.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:        blk.22.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:           blk.22.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:           blk.22.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:             blk.22.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:             blk.23.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:             blk.23.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:             blk.23.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:        blk.23.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:           blk.23.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:           blk.23.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:             blk.23.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:             blk.24.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:             blk.24.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:             blk.24.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:        blk.24.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:           blk.24.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:           blk.24.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:             blk.24.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:             blk.25.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:             blk.25.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:             blk.25.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:        blk.25.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:           blk.25.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:           blk.25.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:             blk.25.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:             blk.26.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:             blk.26.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:             blk.26.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:        blk.26.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:           blk.26.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:           blk.26.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:             blk.26.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:             blk.27.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:             blk.27.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:             blk.27.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:        blk.27.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:           blk.27.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:           blk.27.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:             blk.27.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:             blk.28.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:             blk.28.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:             blk.28.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:        blk.28.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:           blk.28.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:           blk.28.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:             blk.28.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:             blk.29.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:             blk.29.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:             blk.29.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:        blk.29.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:           blk.29.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:           blk.29.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:             blk.29.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:             blk.30.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:             blk.30.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:             blk.30.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:        blk.30.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:           blk.30.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:           blk.30.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:             blk.30.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:             blk.31.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:             blk.31.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:             blk.31.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:        blk.31.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:           blk.31.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:           blk.31.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:             blk.31.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str     \n",
      "llama_model_loader: - kv   1:                               general.name str     \n",
      "llama_model_loader: - kv   2:                       llama.context_length u32     \n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32     \n",
      "llama_model_loader: - kv   4:                          llama.block_count u32     \n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32     \n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32     \n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32     \n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32     \n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32     \n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32     \n",
      "llama_model_loader: - kv  11:                          general.file_type u32     \n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str     \n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr     \n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr     \n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr     \n",
      "llama_model_loader: - kv  16:               general.quantization_version u32     \n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type  f16:    1 tensors\n",
      "llama_model_loader: - type q4_0:    1 tensors\n",
      "llama_model_loader: - type q4_K:  192 tensors\n",
      "llama_model_loader: - type q6_K:   32 tensors\n",
      "llm_load_print_meta: format         = GGUF V1 (support until nov 2023)\n",
      "llm_load_print_meta: arch           = llama\n",
      "llm_load_print_meta: vocab type     = SPM\n",
      "llm_load_print_meta: n_vocab        = 32016\n",
      "llm_load_print_meta: n_merges       = 0\n",
      "llm_load_print_meta: n_ctx_train    = 16384\n",
      "llm_load_print_meta: n_ctx          = 4096\n",
      "llm_load_print_meta: n_embd         = 4096\n",
      "llm_load_print_meta: n_head         = 32\n",
      "llm_load_print_meta: n_head_kv      = 32\n",
      "llm_load_print_meta: n_layer        = 32\n",
      "llm_load_print_meta: n_rot          = 128\n",
      "llm_load_print_meta: n_gqa          = 1\n",
      "llm_load_print_meta: f_norm_eps     = 1.0e-05\n",
      "llm_load_print_meta: f_norm_rms_eps = 1.0e-05\n",
      "llm_load_print_meta: n_ff           = 11008\n",
      "llm_load_print_meta: freq_base      = 1000000.0\n",
      "llm_load_print_meta: freq_scale     = 1\n",
      "llm_load_print_meta: model type     = 7B\n",
      "llm_load_print_meta: model ftype    = mostly Q4_K - Medium\n",
      "llm_load_print_meta: model size     = 6.74 B\n",
      "llm_load_print_meta: general.name   = LLaMA\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 2 '</s>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.09 MB\n",
      "llm_load_tensors: mem required  = 4038.96 MB (+ 2048.00 MB per state)\n",
      "...............................................................................................\n",
      "llama_new_context_with_model: kv self size  = 2048.00 MB\n",
      "llama_new_context_with_model: compute buffer total size =  281.47 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ParisTest passed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   983.78 ms\n",
      "llama_print_timings:      sample time =     0.88 ms /     2 runs   (    0.44 ms per token,  2275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =   983.74 ms /    12 tokens (   81.98 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:        eval time =   155.82 ms /     1 runs   (  155.82 ms per token,     6.42 tokens per second)\n",
      "llama_print_timings:       total time =  1145.69 ms\n"
     ]
    }
   ],
   "source": [
    "from LLM.LLaMaQuant import LLaMaQuant\n",
    "\n",
    "llama = LLaMaQuant()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hey! How can I help you today?<"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   983.78 ms\n",
      "llama_print_timings:      sample time =     5.57 ms /    11 runs   (    0.51 ms per token,  1975.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3677.18 ms /    57 tokens (   64.51 ms per token,    15.50 tokens per second)\n",
      "llama_print_timings:        eval time =  1549.42 ms /    10 runs   (  154.94 ms per token,     6.45 tokens per second)\n",
      "llama_print_timings:       total time =  5260.93 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Hello', 'text': ' Hey! How can I help you today?<'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama.respond(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 404 - {\"message\":\"Not Found\",\"documentation_url\":\"https://docs.github.com/rest\"}\n",
      "No discussions found.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def get_last_github_discussion(owner, repo, token):\n",
    "    # Construct the API URL\n",
    "    api_url = f\"https://api.github.com/repos/{owner}/{repo}/discussions\"\n",
    "\n",
    "    # Set up the headers with the token for authentication\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Accept\": \"application/vnd.github.v3+json\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Make the API request to get discussions\n",
    "        response = requests.get(api_url, headers=headers)\n",
    "\n",
    "        # Check if the request was successful (status code 200)\n",
    "        if response.status_code == 200:\n",
    "            discussions = json.loads(response.text)\n",
    "\n",
    "            # Check if there are any discussions\n",
    "            if discussions:\n",
    "                # Sort discussions by creation date in descending order (most recent first)\n",
    "                discussions.sort(key=lambda x: x[\"created_at\"], reverse=True)\n",
    "\n",
    "                # Return the most recent discussion\n",
    "                return discussions[0]\n",
    "            else:\n",
    "                return None  # No discussions found\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Replace with your GitHub repository owner, repository name, and personal access token\n",
    "owner = \"silverkeytech\"\n",
    "repo = \"summer-2023\"\n",
    "token = \"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\"\n",
    "\n",
    "discussion = get_last_github_discussion(owner, repo, token)\n",
    "\n",
    "if discussion:\n",
    "    print(f\"Last GitHub Discussion:\")\n",
    "    print(f\"Title: {discussion['title']}\")\n",
    "    print(f\"Created At: {discussion['created_at']}\")\n",
    "    print(f\"URL: {discussion['html_url']}\")\n",
    "else:\n",
    "    print(\"No discussions found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
